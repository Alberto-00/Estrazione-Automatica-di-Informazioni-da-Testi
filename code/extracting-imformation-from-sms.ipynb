{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge spacy\n",
    "!conda install -c conda-forge cupy\n",
    "!pip install spacy_transformers\n",
    "\n",
    "# Scegli uno tra:\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_md\n",
    "!python -m spacy download en_core_web_lg\n",
    "!python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T16:19:56.734589477Z",
     "start_time": "2023-12-26T16:19:56.730733200Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "    \n",
    "# with open('dataset/SMS-NER-Dataset-110-Annotations/annotations.json', 'r') as file:\n",
    "#    data = json.load(file)\n",
    "    \n",
    "with open('dataset/SMS-NER-Dataset-165-Annotations/annotations_new.json', 'r') as file:\n",
    "     data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T16:19:58.337752545Z",
     "start_time": "2023-12-26T16:19:58.326741154Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data['annotations']\n",
    "data = [tuple(i) for i in data]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data, test_size = 0.2, random_state = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T16:20:00.568744602Z",
     "start_time": "2023-12-26T16:20:00.564618573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Paytm login detected from a new device at 03:14 PM, 06 May. Not you? To logout from all devices, click: https://ap.p y.tm/ys3MtK or report fraud @1800120130',\n",
       " {'entities': [[0, 5, 'TITLE'], [6, 20, 'PURPOSE'], [42, 59, 'TIME']]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Paytm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " login detected from a new device at \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    03:14 PM,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    06 May\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". Not you? To logout from all devices, click: https://ap.p y.tm/ys3MtK or report fraud @1800120130</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "labels = nlp(train_data[0][0])\n",
    "displacy.render(labels, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T16:20:03.118803765Z",
     "start_time": "2023-12-26T16:20:03.109527768Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in train_data:\n",
    "    if not i[1]['entities']:\n",
    "        i[1]['entities'] = [(0, 0, 'PERSON')]\n",
    "    else:\n",
    "        for j in range(len(i[1]['entities'])):\n",
    "            i[1]['entities'][j] = tuple(i[1]['entities'][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T16:20:04.753038062Z",
     "start_time": "2023-12-26T16:20:04.748778780Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in test_data:\n",
    "    if not i[1]['entities']:\n",
    "        i[1]['entities'] = [(0, 0, 'PERSON')]\n",
    "    else:\n",
    "        for j in range(len(i[1]['entities'])):\n",
    "            i[1]['entities'][j] = tuple(i[1]['entities'][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T16:20:06.231005176Z",
     "start_time": "2023-12-26T16:20:06.224593881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 33\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T16:20:10.037469916Z",
     "start_time": "2023-12-26T16:20:08.179811361Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 132/132 [00:00<00:00, 2385.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 33/33 [00:00<00:00, 1664.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "\n",
    "def make_doc_for_data(data):\n",
    "    nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "    db = DocBin() # create a DocBin object\n",
    "    for text, annot in tqdm(data): # data in previous format\n",
    "        if len(text) > 512:\n",
    "            continue\n",
    "        doc = nlp.make_doc(text) # create doc object from text\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print(\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents # label the text with the ents\n",
    "        db.add(doc)\n",
    "        \n",
    "    return db\n",
    "\n",
    "make_doc_for_data(train_data).to_disk(\"train.spacy\") # save the docbin object\n",
    "make_doc_for_data(test_data).to_disk(\"test.spacy\") # save the docbin object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T16:20:50.057885740Z",
     "start_time": "2023-12-26T16:20:44.839173446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;2m✔ Auto-filled config with all values\u001B[0m\n",
      "\u001B[38;5;2m✔ Saved config\u001B[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config dataset/SMS-NER-Dataset-165-Annotations/base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-26T16:21:52.177191103Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;4mℹ Saving to output directory: output\u001B[0m\n",
      "\u001B[38;5;4mℹ Using GPU: 0\u001B[0m\n",
      "\u001B[1m\n",
      "=========================== Initializing pipeline ===========================\u001B[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001B[38;5;2m✔ Initialized pipeline\u001B[0m\n",
      "\u001B[1m\n",
      "============================= Training pipeline =============================\u001B[0m\n",
      "\u001B[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001B[0m\n",
      "\u001B[38;5;4mℹ Initial learn rate: 0.0\u001B[0m\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "  0       0        2946.75    910.18    0.20    0.11    1.15    0.00\n",
      " 66     200      134052.61  64222.62   71.04   67.71   74.71    0.71\n",
      "133     400        1100.12   1503.39   73.63   70.53   77.01    0.74\n",
      "200     600         390.10    692.99   75.98   73.91   78.16    0.76\n",
      "266     800         308.70    586.18   72.93   70.21   75.86    0.73\n",
      "333    1000         342.33    576.86   72.83   69.07   77.01    0.73\n",
      "400    1200         307.79    561.22   75.82   72.63   79.31    0.76\n",
      "466    1400         297.36    535.99   73.03   71.43   74.71    0.73\n",
      "533    1600         306.49    541.03   75.28   73.63   77.01    0.75\n",
      "600    1800         311.57    547.21   75.00   71.13   79.31    0.75\n",
      "666    2000         305.07    535.40   74.73   71.58   78.16    0.75\n",
      "733    2200         600.89    578.38   75.82   72.63   79.31    0.76\n",
      "\u001B[38;5;2m✔ Saved pipeline to output directory\u001B[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output --paths.train train.spacy --paths.dev test.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;4mℹ Using GPU: 0\u001B[0m\n",
      "\u001B[1m\n",
      "================================== Results ==================================\u001B[0m\n",
      "\n",
      "TOK     100.00\n",
      "NER P   73.91 \n",
      "NER R   78.16 \n",
      "NER F   75.98 \n",
      "SPEED   483   \n",
      "\n",
      "\u001B[1m\n",
      "=============================== NER (per type) ===============================\u001B[0m\n",
      "\n",
      "               P        R        F\n",
      "OTP        87.50    77.78    82.35\n",
      "PURPOSE    60.00    65.22    62.50\n",
      "TITLE      71.88    76.67    74.19\n",
      "MONEY      75.00    81.82    78.26\n",
      "TRANSAC   100.00   100.00   100.00\n",
      "TIME       83.33   100.00    90.91\n",
      "\n",
      "/home/musimathicslab/anaconda3/envs/cancer/lib/python3.9/site-packages/spacy/displacy/__init__.py:213: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n",
      "\u001B[38;5;2m✔ Generated 25 parses as HTML\u001B[0m\n",
      "/media/musimathicslab/My_Passport/estrazione-info-sms/trf\n",
      "\u001B[38;5;2m✔ Saved results to --code\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy benchmark accuracy model-165/trf/output/model-best model-165/test.spacy --output --code --gold-preproc --gpu-id 0 --displacy-path model-165/trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/musimathicslab/Desktop/Estrazione-Automatica-di-Informazioni-da-Testi/code/model.zip'"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download model-best for future use\n",
    "import shutil\n",
    "shutil.make_archive('model', 'zip', 'output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
